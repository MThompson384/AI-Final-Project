{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd199ad5-4360-4ab8-ad46-1acfc0e5614e",
   "metadata": {},
   "source": [
    "# Carbon Prediction: Estimating Bearing AI's Model\n",
    "### Authors: William Olichney, Precious Ndunduri, Micah Thompson, Luke White\n",
    "### Created for the William and Mary Master of Science in Business Analytics AI Class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5594e3-8534-4254-b647-328e13442f24",
   "metadata": {},
   "source": [
    "### Bearing AI\n",
    "\n",
    "Bearing AI has created an AI model that is advertised at being more effective than physics based models in predicting carbon emissions for martime shipping companies. As the European Union's Emission Trading System will require companies to account for 100% of their carbon emissions with a carbon credit, this Bearing AI model could be in high demand as maritime companies will need to accurately budget for this new environmental regulation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e30ac6d-16fc-476d-8d48-94ca4ee38cf5",
   "metadata": {},
   "source": [
    "### Our code\n",
    "While our team does not have access to Bearing AI's model, this code is an attempt to approximate that model, in order to demonstrate how AI and statistical models make an important impact in aiding decision making.\n",
    "\n",
    "#### Simulated Data\n",
    "Using the Numpy library, we generated data of what ships **may** look like: Their speed, cargo weights, and fuel type. Then, we created formulas that would \"create emissions\" from those speed, weight, and fuel type metrics. In reality, someone would need to record how many tonnes of carbon a ship emmitted on voyage, the metrics of their ship, then this data could be used to feed into a statistical model.\n",
    "\n",
    "This code is not to say this is what Bearing AI's model does, but it attempts to accomplish a similar goal: Predict carbon emissions for a potential voyage based off of historical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73d48385-d1e2-4249-b805-0b98708d1935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 4.5718 - mae: 1.7217 \n",
      "Test MAE: 1.68 metric tons of CO₂\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step\n",
      "Predicted emissions: 23.59 metric tons of CO₂\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Simulate some fake data\n",
    "np.random.seed(42)\n",
    "n_samples = 1000\n",
    "\n",
    "#Features: speed (knots), cargo_weight (tons), fuel_type (0: diesel, 1: LNG)\n",
    "speed = np.random.uniform(10, 25, n_samples)\n",
    "cargo_weight = np.random.uniform(5000, 20000, n_samples)\n",
    "fuel_type = np.random.choice([0, 1], size=n_samples)\n",
    "\n",
    "#Simulated emissions formula\n",
    "#Diesel emits more than LNG. Emissions increase with weight and speed.\n",
    "emissions = (\n",
    "    0.2 * speed +\n",
    "    0.0005 * cargo_weight +\n",
    "    (fuel_type * 0.5 + 1.0) * 10 +\n",
    "    np.random.normal(0, 2, n_samples)  # noise\n",
    ")\n",
    "\n",
    "#Create DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'speed': speed,\n",
    "    'cargo_weight': cargo_weight,\n",
    "    'fuel_type': fuel_type,\n",
    "    'emissions': emissions\n",
    "})\n",
    "\n",
    "#Split features and label\n",
    "X = df[['speed', 'cargo_weight', 'fuel_type']].values\n",
    "y = df['emissions'].values\n",
    "\n",
    "#Normalize the input features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "#Split into train/test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#Define a simple neural network model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dense(8, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)  # single output: predicted emissions\n",
    "])\n",
    "\n",
    "#Compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "#Train the model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=16, verbose=0)\n",
    "\n",
    "#Evaluate\n",
    "loss, mae = model.evaluate(X_test, y_test)\n",
    "print(f\"Test MAE: {mae:.2f} metric tons of CO₂\")\n",
    "\n",
    "#Predict for a new ship\n",
    "new_ship = np.array([[18, 12000, 1]])  # 18 knots, 12,000 tons, LNG\n",
    "new_ship_scaled = scaler.transform(new_ship)\n",
    "predicted_emission = model.predict(new_ship_scaled)\n",
    "print(f\"Predicted emissions: {predicted_emission[0][0]:.2f} metric tons of CO₂\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367f01f0-9770-4ca1-9cb2-a197c1b0cf73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
